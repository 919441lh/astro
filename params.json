{"name":"Astro","tagline":"High performance SQL layer over HBase by using Spark SQL framework","body":"## Astro: Fast SQL on HBase using SparkSQL\r\n\r\nAstro is fully distributed SQL engine on HBase by leveraging Spark ecosystem. It enables systematic and powerful handling of data pruning, intelligent scan, and pushdowns like custom filters and coprocessor, and make more traditional RDBMS capabilities possible.\r\n![ASTRO](http://ravipesala.github.io/astro/images/astro_architecture.png)\r\n\r\n## Why Astro\r\n\r\nHBase is a very useful big data store but its access mechanism is very primitive and only through client-side APIs, Map/Reduce interfaces and interactive shells. Astro provides SQL layer over Hbase, so it takes your SQL query, compiles it into optimized Spark plan and in turn it does series of HBase scans to result sets.User do not require to write any complex client code to access HBase tables.\r\nFor example,to count rows in Hbase table we need to write following code:\r\n```\r\npublic class MyAggregationClient {\r\n    private static final byte[] TABLE_NAME = Bytes.toBytes(\"CNCC_Demo\");\r\n    private static final byte[] CF = Bytes.toBytes(\"f1\");\r\n    public static void main(String[] args) throws Throwable \r\n    {\r\n        Configuration customConf = new Configuration();\r\n        customConf.setStrings(\"hbase.zookeeper.quorum\",\"node0,node1,node2\");\r\n        customConf.setLong(\"hbase.rpc.timeout\", 600000);\r\n        customConf.setLong(\"hbase.client.scanner.caching\", 1000);\r\n        Configuration configuration = HBaseConfiguration.create(customConf);\r\n        AggregationClient aggregationClient = new AggregationClient(configuration);\r\n        Scan scan = new Scan();        \r\n        scan.addFamily(CF);\r\n        long rowCount = aggregationClient.rowCount(TABLE_NAME, null, scan);\r\n        System.out.println(\"row count is \" + rowCount);    \r\n     }\r\n}\r\n```\r\nBut if we use Astro,create table schema and just one SQL query:\r\n```\r\nCREATE TABLE CNCC_Demo (\r\n      index          INTEGER,\r\n      event_time     STRING,\r\n      country        STRING,\r\n      site           STRING,\r\n      PRIMARY KEY(index))\r\n      MAPPED BY (CNCC_Demo, COLS=   [event_time=f1.c1,country=f1.c2,site=f2.c1]);\r\nselect  count(*)  from CNCC_Demo;\r\n```\r\n\r\n## Quick Start\r\n\r\nThe easiest way to start using Astro is through the shell:\r\n\r\n## Interactive Scala Shell\r\n\r\nIn this shell Spark context and as well as HBaseSQLContext is already created, launch the Astro shell as per the following method, and in this shell should be SQL apart from HELP and EXIT.\r\n```\r\n>./bin/hbase-sql\r\nWelcome to hbaseql CLI\r\n\r\nastro>show tables;\r\nOK\r\n+---------+-----------+\r\n|tableName|isTemporary|\r\n+---------------------+\r\n|Employee |      false|\r\n+---------------------+\r\n\r\nTime taken : 1.231 seconds\r\nastro>help;\r\nUsage: HELP Statement\r\n      Statement:\r\n         CREATE | DROP | ALTER | LOAD | SELECT | INSERT | DESCRIBE | SHOW\r\n```\r\n\r\n## Python Shell\r\n\r\nFirst, add the spark-hbase jar to the SPARK_CLASSPATH in the $SPARK_HOME/conf directory, as follows:\r\n```\r\nSPARK_CLASSPATH=$SPARK_CLASSPATH:/spark-hbase-root-dir/target/spark-sql-on-hbase-1.0.0.jar\r\n```\r\nThen go to the Astro installation directory and launch the Astro shell:\r\n```\r\n./bin/pyspark-hbase\r\n```\r\nA successful message is as follows:\r\nYou are using Spark SQL on HBase! HBaseSQLContext is available as hsqlContext.\r\n\r\nTo run a python script, the PYTHONPATH environment should be set to the \"python\" directory of the Spark-HBase installation. For example,\r\n```\r\nexport PYTHONPATH=/root-of-Spark-HBase/python\r\n```\r\n\r\n## Fork and Contribute\r\nThis is an 100% open source project, we are always open to people who want to use the system or contribute to it. \r\nThis guide document introduce [how to contribute to Astro](https://github.com/HuaweiBigData/astro/wiki/How-to-contribute-to-Astro).","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}