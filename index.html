<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Astro by HuaweiBigData</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Astro</h1>
      <h2 class="project-tagline">High performance SQL layer over HBase by using Spark SQL framework</h2>
      <a href="https://github.com/HuaweiBigData/astro" class="btn">View on GitHub</a>
      <a href="https://github.com/HuaweiBigData/astro/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/HuaweiBigData/astro/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h2>
<a id="astro-fast-sql-on-hbase-using-sparksql" class="anchor" href="#astro-fast-sql-on-hbase-using-sparksql" aria-hidden="true"><span class="octicon octicon-link"></span></a>Astro: Fast SQL on HBase using SparkSQL</h2>

<p>Astro is fully distributed SQL engine on HBase by leveraging Spark ecosystem. It enables systematic and powerful handling of data pruning, intelligent scan, and pushdowns like custom filters and coprocessor, and make more traditional RDBMS capabilities possible.
<img src="http://ravipesala.github.io/astro/images/astro_architecture.png" alt="ASTRO"></p>

<h2>
<a id="why-astro" class="anchor" href="#why-astro" aria-hidden="true"><span class="octicon octicon-link"></span></a>Why Astro</h2>

<p>HBase is a very useful big data store but its access mechanism is very primitive and only through client-side APIs, Map/Reduce interfaces and interactive shells. Astro provides SQL layer over Hbase, so it takes your SQL query, compiles it into optimized Spark plan and in turn it does series of HBase scans to result sets.User do not require to write any complex client code to access HBase tables.</p>

<p>For example,to count rows in Hbase table we need to write following code:</p>

<p><code>public class MyAggregationClient {</code>
    <code>private static final byte[] TABLE_NAME = Bytes.toBytes("CNCC_Demo");</code>
    <code>private static final byte[] CF = Bytes.toBytes("f1");</code>
    <code>public static void main(String[] args) throws Throwable {</code>
        <code>Configuration customConf = new Configuration();</code>
        <code>customConf.setStrings("hbase.zookeeper.quorum","node0,node1,node2");</code>
        <code>customConf.setLong("hbase.rpc.timeout", 600000);</code>
        <code>customConf.setLong("hbase.client.scanner.caching", 1000);</code>
        <code>Configuration configuration = HBaseConfiguration.create(customConf);</code>
        <code>AggregationClient aggregationClient = new AggregationClient(configuration);</code>
        <code>Scan scan = new Scan();        scan.addFamily(CF);</code>
        <code>long rowCount = aggregationClient.rowCount(TABLE_NAME, null, scan);</code>
        <code>System.out.println("row count is " + rowCount);    }}</code></p>

<p>But if we use Astro,create table schema and just one SQL query:</p>

<p><code>CREATE TABLE CNCC_Demo (</code>
      <code>index          INTEGER,</code>
      <code>event_time     STRING,</code>
      <code>country        STRING,</code>
      <code>site           STRING,</code>
      <code>PRIMARY KEY(index))</code>
      <code>MAPPED BY (CNCC_Demo, COLS=   [event_time=f1.c1,country=f1.c2,site=f2.c1]);</code>
<code>select  count(*)  from CNCC_Demo;</code></p>

<h2>
<a id="quick-start" class="anchor" href="#quick-start" aria-hidden="true"><span class="octicon octicon-link"></span></a>Quick Start</h2>

<p>The easiest way to start using Astro is through the shell:</p>

<p>Interactive Scala Shell</p>

<p>In this shell Spark context and as well as HBaseSQLContext is already created. All the commands which are issued in this shell should be SQL apart from HELP and EXIT.</p>

<blockquote>
<p>./bin/hbase-sql
Welcome to hbaseql CLI
astro&gt;show tables;
OK
+---------+-----------+
|tableName|isTemporary|
+---------------------+
|Employee |      false|
+---------------------+</p>
</blockquote>

<p>Time taken : 1.231 seconds
astro&gt;help;
Usage: HELP Statement
      Statement:
         CREATE | DROP | ALTER | LOAD | SELECT | INSERT | DESCRIBE | SHOW
Python Shell</p>

<p>First, add the spark-hbase jar to the SPARK_CLASSPATH in the $SPARK_HOME/conf directory, as follows:</p>

<p>SPARK_CLASSPATH=$SPARK_CLASSPATH:/spark-hbase-root-dir/target/spark-sql-on-hbase-1.0.0.jar
Then go to the Astro installation directory and issue</p>

<p>./bin/pyspark-hbase
A successfull message is as follows:</p>

<p>You are using Spark SQL on HBase!!! HBaseSQLContext available as hsqlContext.</p>

<p>To run a python script, the PYTHONPATH environment should be set to the "python" directory of the Spark-HBase installation. For example,</p>

<p>export PYTHONPATH=/root-of-Spark-HBase/python
Note that the shell commands are not included in the Zip file of the Spark release. They are for developers' use only for this version of 1.0.0. Instead, users can use "$SPARK_HOME/bin/spark-shell --packages Huawei-Spark/Spark-SQL-on-HBase:1.0.0" for SQL shell or "$SPARK_HOME/bin/pyspark --packages Huawei-Spark/Spark-SQL-on-HBase:1.0.0" for Python shell.</p>

<h2>
<a id="fork-and-contribute" class="anchor" href="#fork-and-contribute" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fork and Contribute</h2>

<p>This is an 100% open source project, we are always open to people who want to use the system or contribute to it. 
This guide document introduce <a href="https://github.com/HuaweiBigData/astro/wiki/How-to-contribute-to-Astro">how to contribute to Astro</a>.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/HuaweiBigData/astro">Astro</a> is maintained by <a href="https://github.com/HuaweiBigData">HuaweiBigData</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
